{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Plaintext Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     C:\\Users\\rosha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('genesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260396\n",
      "['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth']\n"
     ]
    }
   ],
   "source": [
    "genesis_words = genesis.words()\n",
    "filtered_words = [word for word in genesis_words if word.isalpha()]\n",
    "\n",
    "print(len(filtered_words))\n",
    "print(filtered_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_blocks(word_list):\n",
    "    word_str = \"\".join(word_list)\n",
    "    blocked_arr = []\n",
    "    \n",
    "    for i in range(0, len(word_str), 5):\n",
    "        block = word_str[i:i+5].lower()\n",
    "\n",
    "        if len(block) == 5:\n",
    "            blocked_arr.append(block)\n",
    "        else:\n",
    "            diff = 5 - len(block)\n",
    "            padded_block = block + \"x\" * diff\n",
    "            blocked_arr.append(padded_block)\n",
    "\n",
    "    return blocked_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Inthe', 'begin', 'ningG', 'odcre', 'atedt', 'hehea', 'venan', 'dthee', 'arthA', 'ndthe']\n"
     ]
    }
   ],
   "source": [
    "pt_blocks = make_blocks(filtered_words)\n",
    "\n",
    "print(pt_blocks[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plaintext-Ciphertext dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caesar_encrypt(text, key):\n",
    "    result = \"\"\n",
    "\n",
    "    # traverse text\n",
    "    for i in range(len(text)):\n",
    "        char = text[i]\n",
    "\n",
    "        result += chr((ord(char) + key - 97) % 26 + 97)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PpdslyypyxpclyotwyNslcljl\n"
     ]
    }
   ],
   "source": [
    "cipher = caesar_encrypt(\"Eesha ne mera dil Charaya\", key=11)\n",
    "print(cipher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function now returns [[pt, ct, key], [pt, ct, key]]\n",
    "#instead of [[pt, pt, pt], [ct, ct, ct], key] which is big yikes when training\n",
    "\n",
    "#The function now also generates a random key for each word\n",
    "\n",
    "def pt_ct_dataset(pt_list):\n",
    "    final_list = []\n",
    "\n",
    "    for pt in pt_list:\n",
    "        key = random.randint(1, 25)\n",
    "        ct = caesar_encrypt(pt, key)\n",
    "        final_list.append([pt, ct, key])\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def let2num(letter):\n",
    "    return ord(letter)\n",
    "\n",
    "def encode(pt_ct_key_list):\n",
    "    encoded_list = []\n",
    "\n",
    "    for pairs in pt_ct_key_list:\n",
    "        encoded_pt_list = []\n",
    "        encoded_ct_list = []\n",
    "        \n",
    "        for char in pairs[0]:\n",
    "            encoded_pt_list.append(ord(char))\n",
    "\n",
    "        for char in pairs[1]:\n",
    "            encoded_ct_list.append(ord(char))\n",
    "\n",
    "        encoded_list.append([encoded_pt_list, encoded_ct_list, pairs[2]])\n",
    "    \n",
    "    return encoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Inthe', 'Otznk', 6], ['begin', 'ortva', 13], ['ningG', 'bwbuU', 14], ['odcre', 'ncbqd', 25], ['atedt', 'unyxn', 20]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pt_ct_dataset(pt_blocks)\n",
    "\n",
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[73, 110, 116, 104, 101], [79, 116, 122, 110, 107], 6], [[98, 101, 103, 105, 110], [111, 114, 116, 118, 97], 13]]\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = encode(dataset)\n",
    "\n",
    "print(encoded_dataset[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-formatting the pt and ct arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[73, 110, 116, 104, 101, 6], [98, 101, 103, 105, 110, 13]]\n",
      "[[79, 116, 122, 110, 107], [111, 114, 116, 118, 97]]\n"
     ]
    }
   ],
   "source": [
    "pt = []\n",
    "ct = []\n",
    "\n",
    "for item in encoded_dataset:\n",
    "    pt.append(item[0] + [item[2]])\n",
    "    ct.append(item[1])\n",
    "\n",
    "print(pt[:2])\n",
    "print(ct[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[73, 110, 116, 104, 101], [79, 116, 122, 110, 107], 6]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98, 101, 103, 105, 110], [111, 114, 116, 118, 97], 13]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ditto_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
