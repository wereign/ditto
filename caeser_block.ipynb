{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Plaintext Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     C:\\Users\\rosha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\genesis.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('genesis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260396\n",
      "['In', 'the', 'beginning', 'God', 'created', 'the', 'heaven', 'and', 'the', 'earth']\n"
     ]
    }
   ],
   "source": [
    "genesis_words = genesis.words()\n",
    "filtered_words = [word for word in genesis_words if word.isalpha()]\n",
    "\n",
    "print(len(filtered_words))\n",
    "print(filtered_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_blocks(word_list):\n",
    "    word_str = \"\".join(word_list)\n",
    "    blocked_arr = []\n",
    "    \n",
    "    for i in range(0, len(word_str), 5):\n",
    "        block = word_str[i:i+5]\n",
    "\n",
    "        if len(block) == 5:\n",
    "            blocked_arr.append(block)\n",
    "        else:\n",
    "            diff = 5 - len(block)\n",
    "            padded_block = block + \"x\" * diff\n",
    "            blocked_arr.append(padded_block)\n",
    "\n",
    "    return blocked_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Inthe', 'begin', 'ningG', 'odcre', 'atedt', 'hehea', 'venan', 'dthee', 'arthA', 'ndthe']\n"
     ]
    }
   ],
   "source": [
    "pt_blocks = make_blocks(filtered_words)\n",
    "\n",
    "print(pt_blocks[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plaintext-Ciphertext dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caesar_encrypt(text, key):\n",
    "    result = \"\"\n",
    "\n",
    "    # traverse text\n",
    "    for i in range(len(text)):\n",
    "        char = text[i]\n",
    "\n",
    "        # Encrypt uppercase characters\n",
    "        if (char.isupper()):\n",
    "            result += chr((ord(char) + key - 65) % 26 + 65)\n",
    "\n",
    "        # Encrypt lowercase characters\n",
    "        else:\n",
    "            result += chr((ord(char) + key - 97) % 26 + 97)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PpdslyypyxpclyotwyNslcljl\n"
     ]
    }
   ],
   "source": [
    "cipher = caesar_encrypt(\"Eesha ne mera dil Charaya\", key=11)\n",
    "print(cipher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function now returns [[pt, ct, key], [pt, ct, key]]\n",
    "#instead of [[pt, pt, pt], [ct, ct, ct], key] which is big yikes when training\n",
    "\n",
    "#The function now also generates a random key for each word\n",
    "\n",
    "def pt_ct_dataset(pt_list):\n",
    "    final_list = []\n",
    "\n",
    "    for pt in pt_list:\n",
    "        key = random.randint(1, 25)\n",
    "        ct = caesar_encrypt(pt, key)\n",
    "        final_list.append([pt, ct, key])\n",
    "\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def let2num(letter):\n",
    "    return ord(letter)\n",
    "\n",
    "def encode(str_list):\n",
    "    encoded_list = []\n",
    "\n",
    "    for word in str_list:\n",
    "        encoded_char_list = []\n",
    "        for char in word:\n",
    "            encoded_char_list.append(ord(char))\n",
    "\n",
    "        encoded_list.append(encoded_char_list)\n",
    "\n",
    "    return encoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [[pt, ct, key], [pt, ct, key]]\n",
    "def encode(pt_ct_key_list):\n",
    "    encoded_list = []\n",
    "\n",
    "    for pairs in pt_ct_key_list:\n",
    "        encoded_pt_list = []\n",
    "        encoded_ct_list = []\n",
    "        \n",
    "        for char in pairs[0]:\n",
    "            encoded_pt_list.append(ord(char))\n",
    "\n",
    "        for char in pairs[1]:\n",
    "            encoded_ct_list.append(ord(char))\n",
    "\n",
    "        encoded_list.append([encoded_pt_list, encoded_ct_list, pairs[2]])\n",
    "    \n",
    "    return encoded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Inthe', 'Zekyv', 17], ['begin', 'mprty', 11], ['ningG', 'rmrkK', 4], ['odcre', 'ujixk', 6], ['atedt', 'halka', 7]]\n"
     ]
    }
   ],
   "source": [
    "dataset = pt_ct_dataset(pt_blocks)\n",
    "\n",
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[73, 110, 116, 104, 101], [90, 101, 107, 121, 118], 17], [[98, 101, 103, 105, 110], [109, 112, 114, 116, 121], 11]]\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = encode(dataset)\n",
    "\n",
    "print(encoded_dataset[:2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ditto_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
